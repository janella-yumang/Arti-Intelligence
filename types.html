<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Explorer — Types</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body data-page="types">
  <header>
    <div class="container">
      <nav>
        <a class="brand" href="index.html">AI Explorer</a>
        <div class="nav-links">
          <a href="basics.html" data-page="basics">Basics</a>
          <a href="types.html" data-page="types">Types</a>
          <a href="glossary.html" data-page="glossary">Glossary</a>
          <a href="quiz.html" data-page="quiz">Quiz</a>
        </div>
      </nav>
    </div>
  </header>

  <main class="container">
    <h1 class="section-title">Types of AI</h1>
    <p class="page-intro">AI is often grouped by capability level. Understanding these categories helps separate what exists now from what is still theoretical or far-future speculation.</p>
    
    <section>
      <h2 class="section-title">The Three Main AI Types</h2>
      <div class="cards">
        <article class="card">
          <h3>Narrow AI (Weak AI)</h3>
          <img src="https://images.unsplash.com/photo-1589254065878-42c9da997008?w=800" alt="AI assistant and voice recognition technology" />
          <p>Narrow AI is built for one specific task or limited set of tasks. It cannot transfer its knowledge to different domains. This is the <strong>only form of AI that currently exists</strong> in production.</p>
          <p><strong>Real Examples:</strong></p>
          <ul>
            <li>Voice assistants: Siri, Alexa, Google Assistant</li>
            <li>Recommendation engines: Netflix, Spotify, Amazon</li>
            <li>Face recognition: iPhone Face ID, airport security</li>
            <li>Language translation: Google Translate, DeepL</li>
            <li>Game AI: Chess engines, AlphaGo</li>
            <li>Email spam filters</li>
            <li>Navigation apps: Google Maps, Waze</li>
          </ul>
          <p class="note"><strong>Status:</strong> Widely deployed today across all industries</p>
        </article>
        <article class="card">
          <h3>Artificial General Intelligence (AGI)</h3>
          <img src="https://images.unsplash.com/photo-1677442136019-21780ecad995?w=800" alt="Human brain and AI neural network concept" />
          <p>AGI is a hypothetical AI that could perform any intellectual task at human level across different fields, learn new skills independently, and adapt to entirely new situations—not just one specialized task.</p>
          <p><strong>Characteristics if achieved:</strong></p>
          <ul>
            <li>Transfer learning across multiple domains</li>
            <li>Common sense reasoning</li>
            <li>Understand context and abstract concepts</li>
            <li>Learn from small amounts of data like humans</li>
            <li>Plan and set its own goals</li>
          </ul>
          <p class="note"><strong>Status:</strong> Does not exist yet. Timeline unknown—could be decades or centuries away</p>
        </article>
        <article class="card">
          <h3>Artificial Super Intelligence (ASI)</h3>
          <img src="https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=800" alt="Advanced futuristic AI concept" />
          <p>ASI is a theoretical concept where AI surpasses human intelligence in virtually all domains including creativity, scientific reasoning, social skills, and general wisdom.</p>
          <p><strong>Speculative capabilities:</strong></p>
          <ul>
            <li>Vastly superior problem-solving</li>
            <li>Scientific breakthroughs beyond human reach</li>
            <li>Self-improvement and recursive enhancement</li>
            <li>Mastery of all human knowledge domains</li>
          </ul>
          <p class="note"><strong>Status:</strong> Purely theoretical. Raises serious ethical, safety, and existential questions</p>
        </article>
      </div>
    </section>

    <section>
      <h2 class="section-title">Detailed Comparison</h2>
      <div class="grid-2">
        <article class="card">
          <h3>What Exists Now vs. Future</h3>
          <img src="https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800" alt="AI timeline from present to future" />
          <ul>
            <li><strong>Present Reality:</strong> Only Narrow AI is deployed in real products and services</li>
            <li><strong>Research Stage:</strong> Early AGI research is ongoing but far from realization</li>
            <li><strong>Speculative:</strong> ASI is debated by researchers and philosophers</li>
            <li><strong>Investment Focus:</strong> Most funding goes to improving Narrow AI capabilities</li>
          </ul>
        </article>
        <article class="card">
          <h3>Why These Distinctions Matter</h3>
          <img src="https://images.unsplash.com/photo-1516321318423-f06f85e504b3?w=800" alt="People discussing AI policy and ethics" />
          <ul>
            <li>Sets realistic expectations for current AI systems</li>
            <li>Helps policymakers create appropriate regulations</li>
            <li>Guides education and workforce planning</li>
            <li>Informs ethical discussions and safety research</li>
            <li>Prevents both hype and unfounded fear</li>
          </ul>
        </article>
      </div>
    </section>

    <section>
      <h2 class="section-title">Risk Considerations by Type</h2>
      <div class="cards">
        <article class="card">
          <h3>Narrow AI Risks (Current)</h3>
          <img src="https://images.unsplash.com/photo-1614064641938-3bbee52942c7?w=800" alt="Data privacy and security concerns" />
          <ul>
            <li><strong>Bias:</strong> Training data can encode unfair patterns affecting hiring, lending, criminal justice</li>
            <li><strong>Privacy:</strong> Systems require vast personal data that could be misused or breached</li>
            <li><strong>Overreliance:</strong> People may trust AI decisions without verification</li>
            <li><strong>Job Changes:</strong> Automation affects employment in specific sectors</li>
            <li><strong>Transparency:</strong> Complex models can be hard to audit or explain</li>
          </ul>
          <p><strong>Real incidents:</strong> Biased hiring tools, facial recognition errors, discriminatory ad targeting</p>
        </article>
        <article class="card">
          <h3>AGI Risks (Theoretical)</h3>
          <img src="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800" alt="AI alignment and control research" />
          <ul>
            <li><strong>Alignment:</strong> Ensuring AGI goals match human values and intentions</li>
            <li><strong>Control:</strong> Maintaining human oversight as systems become more autonomous</li>
            <li><strong>Rapid Change:</strong> Society may not adapt quickly enough to widespread AGI</li>
            <li><strong>Economic Disruption:</strong> Potential for massive job displacement across sectors</li>
            <li><strong>Accountability:</strong> Who is responsible when AGI makes harmful decisions?</li>
          </ul>
          <p><strong>Research focus:</strong> AI safety organizations study alignment problems before AGI exists</p>
        </article>
        <article class="card">
          <h3>ASI Risks (Speculative)</h3>
          <img src="https://images.unsplash.com/photo-1676277791608-ac86e45f0c3a?w=800" alt="Futuristic AI governance concept" />
          <ul>
            <li><strong>Existential Risk:</strong> System goals misaligned with human survival</li>
            <li><strong>Loss of Control:</strong> No ability to shut down or contain superintelligent systems</li>
            <li><strong>Unpredictability:</strong> Cannot foresee decisions made by vastly superior intelligence</li>
            <li><strong>Power Concentration:</strong> Whoever develops ASI first gains enormous advantage</li>
            <li><strong>Governance:</strong> No current frameworks for regulating superintelligence</li>
          </ul>
          <p><strong>Debate:</strong> Some experts consider ASI distant/unlikely; others prioritize long-term safety research now</p>
        </article>
      </div>
    </section>

    <section>
      <div class="card">
        <h2 class="section-title">Current Focus: Making Narrow AI Better</h2>
        <div class="grid-2">
          <div>
            <p>Since Narrow AI is the only type we have today, most research and development focuses on:</p>
            <ul>
              <li>Reducing bias and improving fairness</li>
              <li>Making models more explainable and transparent</li>
              <li>Increasing efficiency and reducing energy use</li>
              <li>Protecting user privacy through better techniques</li>
              <li>Building safeguards against misuse</li>
              <li>Creating standards and best practices</li>
            </ul>
            <p class="note">Understanding the difference between Narrow AI (real) and AGI/ASI (future/speculative) helps us focus on solving today's actual AI challenges while preparing thoughtfully for potential future developments.</p>
          </div>
          <div>
            <img src="https://images.unsplash.com/photo-1523961131990-5ea7c61b2107?w=800" alt="AI research and development lab" />
          </div>
        </div>
      </div>
    </section>
  </main>

  <footer>
    AI Explorer • Types page
  </footer>

  <script src="main.js"></script>
</body>
</html>
